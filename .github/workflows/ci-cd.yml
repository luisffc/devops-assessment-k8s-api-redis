name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
    paths:
      - 'api/**'
      - 'helm/**'
      - '.github/workflows/ci-cd.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'api/**'
      - 'helm/**'
      - '.github/workflows/ci-cd.yml'

env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: devops-assessment-dev
  ECR_REPOSITORY: devops-assessment-dev-api
  HELM_CHART_PATH: ./helm/api-redis-stack

permissions:
  id-token: write
  contents: read
  security-events: write

jobs:
  lint-and-test:
    name: Lint and Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: Cache linting tools
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-lint-tools-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-lint-tools-

    - name: Install dependencies
      run: |
        cd api
        pip install -r requirements.txt
        pip install flake8 black isort bandit

    - name: Lint with flake8
      run: |
        cd api
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    - name: Format check with black
      run: |
        cd api
        black --check .

    - name: Import sort check with isort
      run: |
        cd api
        isort --check-only .

    - name: Security check with bandit
      run: |
        cd api
        bandit -r . || true

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        cache-dir: .trivycache

    - name: Cache Trivy DB
      uses: actions/cache@v4
      with:
        path: .trivycache
        key: ${{ runner.os }}-trivy-${{ hashFiles('**/Dockerfile', '**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-trivy-

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: 'trivy-results.sarif'

  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    needs: [lint-and-test, security-scan]
    if: github.ref == 'refs/heads/main'

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/devops-assessment-dev-github-actions-role
        role-session-name: GitHubActions
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}
        tags: |
          type=ref,event=branch
          type=sha,format=long,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build and push Docker image
      id: build
      uses: docker/build-push-action@v6
      with:
        context: ./api
        file: ./api/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64

    - name: Set image reference for scanning
      id: image-ref
      run: |
        # Extract the first tag from the metadata outputs
        FIRST_TAG=$(echo '${{ steps.meta.outputs.tags }}' | head -n1)
        echo "image=${FIRST_TAG}" >> $GITHUB_OUTPUT
        echo "Scanning image: ${FIRST_TAG}"

    - name: Scan Docker image for vulnerabilities
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ steps.image-ref.outputs.image }}
        format: 'sarif'
        output: 'trivy-image-results.sarif'
        cache-dir: .trivycache

    - name: Cache Trivy DB for image scan
      uses: actions/cache@v4
      with:
        path: .trivycache
        key: ${{ runner.os }}-trivy-image-${{ hashFiles('**/Dockerfile', '**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-trivy-image-
          ${{ runner.os }}-trivy-

    - name: Upload image scan results
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: 'trivy-image-results.sarif'

  helm-lint:
    name: Helm Lint
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Cache Helm charts
      uses: actions/cache@v4
      with:
        path: |
          ${{ env.HELM_CHART_PATH }}/charts
          ${{ env.HELM_CHART_PATH }}/Chart.lock
        key: ${{ runner.os }}-helm-${{ hashFiles('**/Chart.yaml', '**/Chart.lock') }}
        restore-keys: |
          ${{ runner.os }}-helm-

    - name: Set up Helm
      uses: azure/setup-helm@v4
      with:
        version: '3.18.3'

    - name: Add Bitnami Helm repository
      run: |
        helm repo add bitnami https://charts.bitnami.com/bitnami
        helm repo update

    - name: Update Helm dependencies
      run: |
        cd ${{ env.HELM_CHART_PATH }}
        if [ ! -f Chart.lock ] || ! helm dependency build --skip-refresh; then
          helm dependency update
        fi

    - name: Lint Helm chart
      run: |
        cd ${{ env.HELM_CHART_PATH }}
        helm lint .

    - name: Template Helm chart
      run: |
        cd ${{ env.HELM_CHART_PATH }}
        helm template test-release .

  deploy:
    name: Deploy to Kubernetes
    runs-on: ubuntu-latest
    needs: [build-and-push, helm-lint]
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Cache Helm charts for deployment
      uses: actions/cache@v4
      with:
        path: |
          ${{ env.HELM_CHART_PATH }}/charts
          ${{ env.HELM_CHART_PATH }}/Chart.lock
        key: ${{ runner.os }}-helm-deploy-${{ hashFiles('**/Chart.yaml', '**/Chart.lock') }}
        restore-keys: |
          ${{ runner.os }}-helm-deploy-
          ${{ runner.os }}-helm-

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/devops-assessment-dev-github-actions-role
        role-session-name: GitHubActions
        aws-region: ${{ env.AWS_REGION }}

    - name: Set up kubectl
      uses: azure/setup-kubectl@v4

    - name: Set up Helm
      uses: azure/setup-helm@v4
      with:
        version: '3.18.3'

    - name: Update kubeconfig for EKS
      run: |
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

        # Verify connection
        kubectl get nodes

    - name: Add Bitnami Helm repository
      run: |
        helm repo add bitnami https://charts.bitnami.com/bitnami
        helm repo update

    - name: Deploy application
      run: |
        cd ${{ env.HELM_CHART_PATH }}
        if [ ! -f Chart.lock ] || ! helm dependency build --skip-refresh; then
          helm dependency update
        fi

        # Check if namespace exists, if not create it
        kubectl get namespace api-namespace || kubectl create namespace api-namespace

        helm upgrade --install api-redis . \
          --namespace api-namespace \
          --set api.image.repository=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.ECR_REPOSITORY }} \
          --set api.image.tag=main-${{ github.sha }} \
          --timeout=5m

        # Debug: Check the deployment status
        echo "üîç Checking deployment status..."
        kubectl get pods,svc -n api-namespace -o wide

        # Check events for any issues
        echo "üîç Checking recent events..."
        kubectl get events -n api-namespace --sort-by='.lastTimestamp' | tail -10

        # Check pod logs if any pods exist
        echo "üîç Checking pod logs..."
        kubectl get pods -n api-namespace -o name | head -3 | xargs -I {} kubectl logs {} -n api-namespace --tail=50 || true

        # Debug: Check if the latest image has the right dependencies
        echo "üîç Debugging image dependencies..."
        kubectl get pods -n api-namespace -l app.kubernetes.io/name=python-api -o name | head -1 | xargs -I {} kubectl exec {} -n api-namespace -- pip list | grep gunicorn || echo "Gunicorn not found in container"

    - name: Verify deployment
      run: |
        echo "üîç Final deployment verification..."

        # Function to wait for pods with timeout
        wait_for_pods() {
          local label=$1
          local name=$2
          local timeout=${3:-300}
          local interval=10
          local elapsed=0

          echo "‚è≥ Waiting for $name to be ready..."
          while [ $elapsed -lt $timeout ]; do
            local ready=$(kubectl get pods -n api-namespace -l "$label" -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' 2>/dev/null | grep -c "True" || echo "0")
            if [ "$ready" -gt "0" ]; then
              echo "‚úÖ $name is ready ($ready pods)"
              return 0
            fi
            echo "‚è≥ $name not ready yet... (${elapsed}s/${timeout}s)"
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          echo "‚ö†Ô∏è $name readiness timeout after ${timeout}s"
          return 1
        }

        # Wait for both services
        wait_for_pods "app.kubernetes.io/name=redis" "Redis" &
        REDIS_PID=$!
        wait_for_pods "app.kubernetes.io/name=python-api" "API" &
        API_PID=$!

        # Wait for both background processes
        wait $REDIS_PID
        REDIS_STATUS=$?
        wait $API_PID
        API_STATUS=$?

        # Check final status
        echo "üìä Final status:"
        kubectl get pods,svc -n api-namespace -o wide

        API_READY=$(kubectl get pods -n api-namespace -l app.kubernetes.io/name=python-api -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' 2>/dev/null | grep -c "True" || echo "0")
        REDIS_READY=$(kubectl get pods -n api-namespace -l app.kubernetes.io/name=redis -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' 2>/dev/null | grep -c "True" || echo "0")

        echo "üîç Readiness: API=$API_READY pods, Redis=$REDIS_READY pods"

        if [ "$API_READY" -gt "0" ] && [ "$REDIS_READY" -gt "0" ]; then
          echo "‚úÖ Deployment successful - Both services are ready"

          # Quick health check
          kubectl get pods -n api-namespace -l app.kubernetes.io/name=python-api -o name | head -1 | \
            xargs -I {} kubectl exec {} -n api-namespace -- curl -sf http://localhost:8080/health > /dev/null && \
            echo "üè• Health check passed" || echo "‚ö†Ô∏è Health check failed"

          # Get LoadBalancer info
          LB_HOSTNAME=$(kubectl get svc -n api-namespace api-redis-api-redis-stack-api -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          LB_IP=$(kubectl get svc -n api-namespace api-redis-api-redis-stack-api -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")

          if [ -n "$LB_HOSTNAME" ] && [ "$LB_HOSTNAME" != "Pending" ]; then
            API_URL="http://$LB_HOSTNAME"
            echo "üöÄ API URL: $API_URL/health"
            echo "::notice title=üöÄ API Deployed Successfully::API is available at $API_URL"
            echo "::notice title=üìç Health Check::$API_URL/health"
            echo "::notice title=üìä Store Data::POST $API_URL/store"
            echo "::notice title=üîë Get Keys::GET $API_URL/keys"
          elif [ -n "$LB_IP" ]; then
            API_URL="http://$LB_IP"
            echo "üöÄ API URL: $API_URL/health"
            echo "::notice title=üöÄ API Deployed Successfully::API is available at $API_URL"
            echo "::notice title=üìç Health Check::$API_URL/health"
            echo "::notice title=üìä Store Data::POST $API_URL/store"
            echo "::notice title=üîë Get Keys::GET $API_URL/keys"
          else
            echo "‚è≥ LoadBalancer provisioning: kubectl get svc -n api-namespace"
            echo "::warning title=‚è≥ LoadBalancer Provisioning::LoadBalancer is still being provisioned. Run 'kubectl get svc -n api-namespace' to check status."
          fi
        else
          echo "‚ùå Deployment incomplete (API:$API_READY, Redis:$REDIS_READY)"
          kubectl describe pods -n api-namespace | grep -A 5 "Events:" || true

          # Exit with warning on timeout, error on failure
          [ "$REDIS_STATUS" -eq 1 ] || [ "$API_STATUS" -eq 1 ] && exit 0 || exit 1
        fi
